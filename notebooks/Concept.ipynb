{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67d748df-3a28-4d2d-b488-e49020627b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "from concept import ConceptModel\n",
    "from sentence_transformers import util\n",
    "from PIL import Image\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cf22b0-0a72-47c8-b6f0-30789c52dcbc",
   "metadata": {},
   "source": [
    "## Prepare Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f9356cf-ddf8-451b-899d-a7e7632322d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we get about 25k images from Unsplash \n",
    "img_folder = 'photos/'\n",
    "if not os.path.exists(img_folder) or len(os.listdir(img_folder)) == 0:\n",
    "    os.makedirs(img_folder, exist_ok=True)\n",
    "    \n",
    "    photo_filename = 'unsplash-25k-photos.zip'\n",
    "    if not os.path.exists(photo_filename):   #Download dataset if does not exist\n",
    "        util.http_get('http://sbert.net/datasets/'+photo_filename, photo_filename)\n",
    "        \n",
    "    #Extract all images\n",
    "    with zipfile.ZipFile(photo_filename, 'r') as zf:\n",
    "        for member in tqdm(zf.infolist(), desc='Extracting'):\n",
    "            zf.extract(member, img_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ec593c-cabf-4828-aca7-1288cd177fea",
   "metadata": {},
   "source": [
    "## Use pre-computed embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b160d8e9-1896-402c-82bc-1f08e9a4d3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_filename = 'unsplash-25k-photos-embeddings.pkl'\n",
    "if not os.path.exists(emb_filename):   #Download dataset if does not exist\n",
    "    util.http_get('http://sbert.net/datasets/'+emb_filename, emb_filename)\n",
    "    \n",
    "with open(emb_filename, 'rb') as fIn:\n",
    "    img_names, img_embeddings = pickle.load(fIn)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39d6041f-e59b-48de-a39b-1fa81ccfeb5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 5000/5000 [00:01<00:00, 2675.67it/s]\n"
     ]
    }
   ],
   "source": [
    "images = [Image.open(\"photos/\"+filepath) for filepath in tqdm(img_names[:5000])]\n",
    "image_names = img_names[:5000]\n",
    "image_embeddings = img_embeddings[:5000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f588128f-1f86-4cc6-b4ac-e329042c998d",
   "metadata": {},
   "source": [
    "## Extract docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40ed906d-ffd3-4bb0-85dd-660102602937",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = fetch_20newsgroups(subset='all',  remove=('headers', 'footers', 'quotes'))['data']\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2)).fit(docs)\n",
    "words = vectorizer.get_feature_names()\n",
    "words = [words[index] for index in np.argpartition(vectorizer.idf_, -50_000)[-50_000:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e821cc-4613-44c9-918d-25107285a3bc",
   "metadata": {},
   "source": [
    "## Concept Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e594eb9-9005-4887-8468-f686e1f911bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64181c97695d413ba03e1f7e96632c35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "concept_model = ConceptModel()\n",
    "concepts = concept_model.fit_transform(images=images, \n",
    "                                       docs=docs,\n",
    "                                       image_names=image_names, \n",
    "                                       image_embeddings=image_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c1da190-cae3-44ac-99c2-6c6b2e94e1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_model.visualize_concepts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bertopic",
   "language": "python",
   "name": "bertopic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
